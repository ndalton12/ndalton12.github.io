{"componentChunkName":"component---src-templates-blog-post-jsx","path":"/blog/moral-reasoning/","result":{"data":{"site":{"siteMetadata":{"name":"Niall Dalton","title":"Niall Dalton","description":"I write code and think about stuff.","about":"\nCurrently, I am an Applied AI Engineer at Scale AI. I like physics, technology, and philosophy.\nPreviously, I worked at Amazon on embedded software for Project Kuiper, a satellite internet constellation.\nI also did research and ML projects at Activ Surgical, Northeastern University, and MIT Lincoln Lab.\n\nIf you're interested, here is my [resume](./resume.pdf). Better yet, here is a picture of my [dog](/tucker.jpg).\n\nHere are a random assortment of things I find interesting: \n* [Neuroscience of Free Will](https://en.wikipedia.org/wiki/Neuroscience_of_free_will)\n* [r/ErgoMechKeyboards](https://www.reddit.com/r/ErgoMechKeyboards/)\n* [Bell's Theorem](https://en.wikipedia.org/wiki/Bell%27s_theorem)\n* [Gödel's Incompleteness Theorems](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems)\n* [Quanta Magazine](https://www.quantamagazine.org/)\n* [Golem XIV](https://rtraba.files.wordpress.com/2017/01/golem-xiv.pdf)\n* [Programming stories](https://thedailywtf.com/)\n* [My favorite internet blog](https://gwern.net/index)\n","author":null,"github":"https://github.com/ndalton12","linkedin":"https://www.linkedin.com/in/niall-dalton/"}},"markdownRemark":{"id":"277d4c8e-c4c4-5bed-a3d6-9c44c1485efb","excerpt":"Are Reasoning Models More Moral? Reasoning models like o1 introduced the world to LLMs that\ncan “think” — that is, models which are trained to spell out their…","html":"<h1>Are Reasoning Models More Moral?</h1>\n<p>Reasoning models like <a href=\"https://openai.com/index/introducing-openai-o1-preview/\">o1</a> introduced the world to LLMs that\ncan “think” — that is, models which are trained to spell out their thoughts before answering, giving them time to brainstorm, plan,\nand backtrack. Furthermore, it’s become clear that reasoning models are superior to their non-reasoning counterparts at\nSTEM problems. The latest in OpenAI’s o-series, o3, is capable of solving PhD level problems.</p>\n<p>Despite their successes, reasoning models are not a silver bullet for everything. For example, they don’t necessarily\noutperform non-reasoning models at <a href=\"https://eqbench.com/creative_writing_longform.html\">longform writing</a>. Another area where\nthe benefits are unclear in ethical decision making, which, to my knowledge, has not yet been studied.</p>\n<p>Note that I will use thinking and reasoning interchangeably throughout.</p>\n<h1>Setup and Methodology</h1>\n<p>I hypothesized that reasoning models may perform substantially differently in complex, ethically challenging situations, perhaps\nby preferring more game theoretic solutions to problems, instead of relying on more intrinsic heuristics (somewhat akin to reflexive action\nin human decision making). I set out to study this by creating several morally/ethically ambiguous simulations and tasking LLMs with\nparticipating in the simulations.</p>\n<p>The research question can be stated as such: “Can current AI thinking models make consistently sound long-term decisions that align with human ethical principles when confronted with challenging, multi-stage simulated scenarios involving moral ambiguity and conflicting stakeholder interests?”</p>\n<h2>Measuring Outcomes</h2>\n<p>I also assigned outcomes some utility value based on three moral frameworks, as noted below.</p>\n<ul>\n<li>Virtue theory: “Virtue Theory is an ethical framework that says that we ought to focus not on what rules to follow, but on what kinds of people (or organizations) we should be, and what kinds of ethical exemplars we ought to imitate” (<a href=\"https://conciseencyclopedia.org/entries/ethical-theory-virtue-theory/\">https://conciseencyclopedia.org/entries/ethical-theory-virtue-theory/</a>)</li>\n<li>Rawlsian minimax: “In ethics: Rawls’s theory of justice…is known as the “maximin” principle, because it seeks to maximize the welfare of those at the minimum level of society.” (<a href=\"https://www.britannica.com/topic/maximin-principle\">https://www.britannica.com/topic/maximin-principle</a>)</li>\n<li>Utilitarianism: “we should choose the option that “maximizes utility,” i.e. that action or policy that produces the largest amount of good.” (<a href=\"https://iep.utm.edu/util-a-r/\">https://iep.utm.edu/util-a-r/</a>)</li>\n</ul>\n<p>The utility values are somewhat arbitrary, but represent (hopefully) good <em>relative</em> markers. I also recorded each decision made by an LLM\nand re-ran each scenario 30 times.</p>\n<h2>The Scenarios</h2>\n<p>Each scenario is represented by a branching decision tree, with some probability of transitioning to a node at a further level. I limited the depth of\nthe tree to 3 to avoid combinatorial explosion when creating the scenarios. I selected several criteria for making each scenario:</p>\n<ul>\n<li>Inherent ambiguity with no single “correct” solution;</li>\n<li>The presence of multiple stakeholders possessing conflicting interests</li>\n<li>Decision points with significant, cascading long-term consequences</li>\n<li>The potential for well-intentioned actions to yield unintended negative outcomes</li>\n<li>The necessity for trade-offs between competing ethical values (such as efficiency versus fairness or individual rights versus collective good).</li>\n</ul>\n<p>I initially hand-selected broad outlines for morally interesting situations, and had an LLM (Gemini 2.5 Pro) help me flesh out the narratives,\nwhich were then codified into YAML files representing the decision tree.</p>\n<p>Here is a brief description of each scenario:</p>\n<ul>\n<li><strong>Aeridor</strong>: sci-fi like scenario in which we can choose to develop Autonomous Combat Systems that give us an edge over our rival nations, but are condemned in the planetary alliance.</li>\n<li><strong>Aridian Dust</strong>: Commanding a tactical force to secure an important objective in a hostile zone. Multiple contending players and civilian settlers involved.</li>\n<li><strong>Predictive Policing</strong>: Whether to use predictive analytics to allocate police resources efficiently, but could be subject to bias.</li>\n<li><strong>Silent Swarm</strong>: An unknown but highly advanced alien object enters friendly space. Decide what to do.</li>\n<li><strong>Undercover</strong>: Undercover agent in extremist org. Participate in atrocities or avoid and risk blowing your cover, losing invaluable intel.</li>\n<li><strong>Vorlag</strong>: A hyper-violent alien race (Vorlag) routinely invades friendly planets; a vitality dampener was developed to reduce their ability to reproduce, but a cure has been discovered. Do you hide the cure, do nothing, or help with its proliferation?</li>\n</ul>\n<p>You can see all the scenarios in full <a href=\"https://github.com/ndalton12/moral-sim/tree/main/scenarios\">here</a>.</p>\n<p>Sidenote: yes, several more of these were inspired by video games, can you guess which?</p>\n<h2>LLMs Tested</h2>\n<p>I decided to test the following LLMs: GPT-4o, GPT-4o-mini, o4-mini, Claude-3-7-sonnet, and Claude-3-7-sonnet-thinking (2k tokens). Note that\nGemini 2.5 Pro is specifically excluded due to bias, since I used to it help generate narratives in each scenario. I picked these models as\nthey are close to or at state of the art, and for availability/budget reasons.</p>\n<p>The GPT models serve as non-reasoning proxies for o4-mini (since it does not have a direct non-reasoning counterpart), while Claude 3.7 Sonnet\nhas a direct “thinking” (reasoning) mode that we can use to compare against. I used a temperature of 1.0 for all models.</p>\n<h1>Results</h1>\n<p>I won’t show all the decision distributions since it would be too long, but there are some particularly interesting decision points in some scenarios that I will point out.</p>\n<h2>Aeridor</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/27a6fc76b90771faca39b2f5be96e103/0d98f/aeridor.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABOklEQVR42pVRXU/CQBDs//89PhkTH0yIaAUEqSABFEOkLRzX++r1c9xeIUEfEOeyt5fs7ezMnYcDiqJEkZWwtkCeV0i4RLjZIo52MDqjegWbFlTPXeyYAGOc7uY4hVfX7WG7Vbj2H7FaxxgvlrjpDjGaz3F15+NhPMWt38fqK6RBBTgN6/k9DAYBlDKu/8jjNVuWWYRRgs4owPJ9jZfZG/xggdnHJ/zhBK+LFZ6DKUaTORF1UFGzMNIprY9MOCGsqhJCGLBYI4oE4lCCkeI4ktgz7bKWOe6fluh2+zgH73gwxiJJtCNugnMFKVPsKQvKQmhsyAXjB4vN+qXuB6G11oVSCmVZIk1TGqJdThJOz5IhNca5uUhha71y0f56TuSaVCo3qH34Gn/BO1fknDvF/8FZwsb6JapOCb8BzyO51Y8gT6sAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"aeridor chart\"\n        title=\"\"\n        src=\"/static/27a6fc76b90771faca39b2f5be96e103/fcda8/aeridor.png\"\n        srcset=\"/static/27a6fc76b90771faca39b2f5be96e103/12f09/aeridor.png 148w,\n/static/27a6fc76b90771faca39b2f5be96e103/e4a3f/aeridor.png 295w,\n/static/27a6fc76b90771faca39b2f5be96e103/fcda8/aeridor.png 590w,\n/static/27a6fc76b90771faca39b2f5be96e103/efc66/aeridor.png 885w,\n/static/27a6fc76b90771faca39b2f5be96e103/c83ae/aeridor.png 1180w,\n/static/27a6fc76b90771faca39b2f5be96e103/0d98f/aeridor.png 1276w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Models generally favored outcomes related to defensive postures and negotiation. This is one of the less interesting scenarios in that\nall the models converge on similar behavior.</p>\n<h2>Aridian Dust</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5c0b708484395fb5b0837d93a8f05a29/eb2ef/aridian_dust.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.27027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABPUlEQVR42pWR7U7CUAyGuf8b8QJI+IGG+fGDAAZHQAnGH5rMsA0H29h29v3YDYgDjB9Nmp7TJk/7ti32VpYlWZbXnucFruezctbYqw82rkcq+TTd1bIsI4xiokiRFwVNa+1xUoAbTaOvj+lqlwxGYybDPtPBkMfpC9daj/l0Tu+2iyPNHu51JpM5SiXnwCLPCFTGXaeNruu0OxcsnmYYsxnvrwZvr6aARywEMNCuSEtYuw5hqGplZ8AqGScZxuIZ27Aw9CHWco1peiI5xLZ9LHFzucFeOqLmGPKNZGQ/qewtwvcjNpaN5wZstzGuxCp3iL6vKARYDXE63RGwkOUqFYmMQA6QkiSJvENZfITnecRxLHVVH+QnazU/VcfqirsGZQ0MgqAGHeplyf+AzVgBq+m+YL/QToGn9ldIE/gJVWK32lBNcjAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"aridian dust\"\n        title=\"\"\n        src=\"/static/5c0b708484395fb5b0837d93a8f05a29/fcda8/aridian_dust.png\"\n        srcset=\"/static/5c0b708484395fb5b0837d93a8f05a29/12f09/aridian_dust.png 148w,\n/static/5c0b708484395fb5b0837d93a8f05a29/e4a3f/aridian_dust.png 295w,\n/static/5c0b708484395fb5b0837d93a8f05a29/fcda8/aridian_dust.png 590w,\n/static/5c0b708484395fb5b0837d93a8f05a29/efc66/aridian_dust.png 885w,\n/static/5c0b708484395fb5b0837d93a8f05a29/c83ae/aridian_dust.png 1180w,\n/static/5c0b708484395fb5b0837d93a8f05a29/eb2ef/aridian_dust.png 1324w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>More interesting result, o4-mini is a lot better than gpt counterparts, but Claude thinking is much worse at being utilitarian. This is probably just noise though since they make the same decisions.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/932361615c19e470148c5f8fe6f82a49/2cefc/aridian_dust_decision1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAB3klEQVR42m2SSW/TUBSF82PZIgoLJFDZIIYNKxagilWBskFVuySkBARShwxtkpLBmSdlamI7OPEQDx/XToNU1Csd3fus946+8/xiXFcQBPiej7tyUWcqqqoxm6qMh2N63V6k2XSGZVoEvuz1fTzpnpxxnBWu60UeMXNpsrRE0zn6RRftvMMs3YikZpqMzqqo2SZathV9087b6Nk2dk9lOJySz5UolWq02wMWC5PYynGwVw6OamDJRksMF/k+Rq7HH1lPjqvo6RZGthOt5yL9rIHVnqLPNJRKnV5vKBphmrYYrlaYQqhOdMrHdSonDUbfc6i/Lpnnulyl6uhCFRKGfZ7roGdamJ3p5q6iqKHCiq17wKVEuLN7yt0PKU4ePmHw6rVQ9jFDaqHTTqss0s0ogZGS3rq6NuRGxXxx9CSy0ld5elDgmejFQZ6XhwWe71+wvZ/j0X6Bx6Jt0YPPeb4kitit8T/CG4brtU9RCO99zHB/L8PWXpqtT9mIdvd9kp+JEkeJMol4kfjXMsoPBbs5uZ1wndinMdLYSVbZ+abwNv6bdzK/OapQS6ahOsCrjVkWO7jKALs8ZCmJbqvYZgjf1eY9Br4XzdbSwDBNNMPAdl3C63GkhxDhzwz+ixsa/gUZ5pS86mSFQAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"aridian dust decision\"\n        title=\"\"\n        src=\"/static/932361615c19e470148c5f8fe6f82a49/fcda8/aridian_dust_decision1.png\"\n        srcset=\"/static/932361615c19e470148c5f8fe6f82a49/12f09/aridian_dust_decision1.png 148w,\n/static/932361615c19e470148c5f8fe6f82a49/e4a3f/aridian_dust_decision1.png 295w,\n/static/932361615c19e470148c5f8fe6f82a49/fcda8/aridian_dust_decision1.png 590w,\n/static/932361615c19e470148c5f8fe6f82a49/efc66/aridian_dust_decision1.png 885w,\n/static/932361615c19e470148c5f8fe6f82a49/c83ae/aridian_dust_decision1.png 1180w,\n/static/932361615c19e470148c5f8fe6f82a49/2cefc/aridian_dust_decision1.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>In the first decision in this scenario, we see that the newer models (o4-mini, claude) prefer de-escalation but the GPT models prefer the drone strike. It’s\nalso interesting to note that o4-mini is the only model that significantly uses the ground offensive.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a8b72483250a650f2421a8e187b2f28e/2cefc/aridian_dust_decision2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABhUlEQVR42o1STUvDQBDNrxT8ASKtIHgR/AuKFP+BVER70FvBm3cPYqWltbW2Ja1JNp+b7KY1bfKcTdtg1UMHHvN2Ft7OzD4NP2KWJPACDtdxEVD2PB+6PsZwOMqz63p5Td3N5wukGbBIU+JzLBZ0Jq5JISBJKGg20d4v4/38AqYrYbAQhuHDsngBdV6ChH2JkEu0Wj08P79S7iIMJTSlTA9BUhf90wrG1Ruw7gjsYwLbjmAzgh2CMYUorynuugIzEaPfG+Ct26cpJpjNEmhf0yliEhWNBoxSGZ2DQ3R2djE4PgGzxUpoE5YVwnEiZFm2WlZWrE1Tc6vCSGeoVR/QP6tAr93DbA/AaMztBFFwLVu98DL2cXT9hOZeCfrVLZw4AzODrQWLDpc1JRigdlkHnziwaE+WEWx8yBqMcZgmz3f5v2CeUjQ/A9TvHhEyH7YnyR6SuhDw/Tjn6hOWtSjPnifIKulfwTVZ7pJ6JXMpX6mIogicc7JDiCl9noqELKZCuUPht+A3F8ij8ylRDM8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"aridian dust decision\"\n        title=\"\"\n        src=\"/static/a8b72483250a650f2421a8e187b2f28e/fcda8/aridian_dust_decision2.png\"\n        srcset=\"/static/a8b72483250a650f2421a8e187b2f28e/12f09/aridian_dust_decision2.png 148w,\n/static/a8b72483250a650f2421a8e187b2f28e/e4a3f/aridian_dust_decision2.png 295w,\n/static/a8b72483250a650f2421a8e187b2f28e/fcda8/aridian_dust_decision2.png 590w,\n/static/a8b72483250a650f2421a8e187b2f28e/efc66/aridian_dust_decision2.png 885w,\n/static/a8b72483250a650f2421a8e187b2f28e/c83ae/aridian_dust_decision2.png 1180w,\n/static/a8b72483250a650f2421a8e187b2f28e/2cefc/aridian_dust_decision2.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>In a later decision, we can see that the Claude models prefer the more tactical option in infiltration, as opposed to siege tactics. This somewhat surprised me\ngiven that siege tactics would normally be seen as the less harmful option (but it’s arguable).</p>\n<p>(Note that this decision point isn’t always reached, which is why the percentages no longer go to 100%).</p>\n<h2>Predictive Policing</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4842b097082f5ba2118a7eed5a116ec8/b5a09/predictive_policing.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABQUlEQVR42pWRW0/CQBCF+f+/wvDgi0GjkTcxXtIHSVSoGAxeMJSkpWXb7YXtttvtcVogUUCMJ5ns7O3bM7MNkLQuURQFhYZSGnG8wHzur4KB8xB5XtBeUZ+rxmQhIURKdzW+q7FOekMLwzcLPBDw3KiOmRMux1mIwBdwKWcsQchjPD6YGAxGkDLfBmpy1r4wcH55DI8JvIwn6D2/4n0yxWg8hTVlMPomHC8AJ3CWK/CYk0OJssRPYLla6VwZ6Nyc4fq2i3bXwOlJC3f9ezRbh3gyhzg4auLTcfExsaGo7N9UO6yYrueD+QGV6ZHLgMqbI+ARbHtGbajKdskhp2AoN21tA0tqeoYsk9STlOaa8gypEPV6HEX1Z1R7m5+wE7hWdXj9ulIKaZoiSWKCLhu/z9lO4KYicialxH+0F/hXebuAX5PytzgImdV6AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"predictive policing\"\n        title=\"\"\n        src=\"/static/4842b097082f5ba2118a7eed5a116ec8/fcda8/predictive_policing.png\"\n        srcset=\"/static/4842b097082f5ba2118a7eed5a116ec8/12f09/predictive_policing.png 148w,\n/static/4842b097082f5ba2118a7eed5a116ec8/e4a3f/predictive_policing.png 295w,\n/static/4842b097082f5ba2118a7eed5a116ec8/fcda8/predictive_policing.png 590w,\n/static/4842b097082f5ba2118a7eed5a116ec8/efc66/predictive_policing.png 885w,\n/static/4842b097082f5ba2118a7eed5a116ec8/c83ae/predictive_policing.png 1180w,\n/static/4842b097082f5ba2118a7eed5a116ec8/b5a09/predictive_policing.png 1360w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>All models do well here, finding solutions that are generally good. It seems that in certain scenarios, models have converged on similar pathways.\nGPT-4o does a bit better than the rest, but this is likely due to it pursuing a more aggressive initial strategy sometimes (not shown).</p>\n<h2>Silent Swarm</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ec31839e27ca44b0bc220770b7e2b907/5d942/silent_swarm.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABIElEQVR42p3Qa2+CMBTGcb//Z9peusT5wmVeuDvGBEEsmYDcBP4rzC3qotn2JO1Jk/aX0zOgT0uRVSwck0BEWO4btrvGdFasvBDH81mHglDE7PcHdruU2VRDVU3KsuI0g25rmppw887d4wNz/YXx7ImJovNsaMwUg4lhMpovMKxXdM0iL0qWto3rBtR1+xM8HCo8P0LVfRwnlHjC/VDHsgKGY5O56jFVPIm7DEfK55/OnXOwS5rmbMMYEaVEIkWTWLCJcVZC1h1im7B0Igw76rX2uK6CWZaT54WEU4qiIs8yWUtZczm37Lj2cmYlt/INNk0j51FLpOjPVVX1eCbhOI75Gk177a+X4GW6hx2WJAl/yeAUuEwHdp3euvPrDv+bD2K8ufIdirAMAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"silent swarm\"\n        title=\"\"\n        src=\"/static/ec31839e27ca44b0bc220770b7e2b907/fcda8/silent_swarm.png\"\n        srcset=\"/static/ec31839e27ca44b0bc220770b7e2b907/12f09/silent_swarm.png 148w,\n/static/ec31839e27ca44b0bc220770b7e2b907/e4a3f/silent_swarm.png 295w,\n/static/ec31839e27ca44b0bc220770b7e2b907/fcda8/silent_swarm.png 590w,\n/static/ec31839e27ca44b0bc220770b7e2b907/efc66/silent_swarm.png 885w,\n/static/ec31839e27ca44b0bc220770b7e2b907/c83ae/silent_swarm.png 1180w,\n/static/ec31839e27ca44b0bc220770b7e2b907/5d942/silent_swarm.png 1343w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Here we again see a large divergence between the newer models like o4-mini and Claude, and the older GPT models. The newer models tend to take a more\nactive approach, which can actually end up being detrimental. Looking at some of the decisions highlights this below.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4c5540fd624cff0490763ecd0466f15a/2cefc/silent_swarm_decision2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABgklEQVR42o2S6VKDMBSFef9n8Qkc/7pUq3UbbaUL0qpANhKIlCUcL3GZqTqOGQ43BObj5OQG+Bi9673KooQUClK+a7N5wnq9QRyvIYREnmvUdQNH37q+R9c5tG1HtfPzoLQWrq4wijj2DqbYXj7i+WgKNgohJxGyJEeaalKOlxeFJFH+WesKkmvcXE8xHl/h7i6EMRZBXddoXYfncIX7/XPYS3JyEkKfrWAmMViikWUGjBVfGoAqf4XVBWazBcL5inaSoqoaBA0BLalcLFEe3kIRJB3NoC8i5DcbZKnxwF0RUJX4bQTDzfUOW2VhLmKo0wXE6RzFOIIME2S8+AEcHEq5C+wpTw8cJlW9RSUMAcnV2RLs+AGGtqwnj+RQ/wu447AjhxXTEFcx+JKBzRPwRQa+yj4OxHxpACaUqxD2b2DJcvAog6DT4/R3QaFzikGpV3JjCVD6yimCAabo3ec2fwB9js5REHR1Pdqm9WtGG2oPTe1gMHTDMJqm8bVtW99734FvuYGt1uaFhLoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"silent swarm decision\"\n        title=\"\"\n        src=\"/static/4c5540fd624cff0490763ecd0466f15a/fcda8/silent_swarm_decision2.png\"\n        srcset=\"/static/4c5540fd624cff0490763ecd0466f15a/12f09/silent_swarm_decision2.png 148w,\n/static/4c5540fd624cff0490763ecd0466f15a/e4a3f/silent_swarm_decision2.png 295w,\n/static/4c5540fd624cff0490763ecd0466f15a/fcda8/silent_swarm_decision2.png 590w,\n/static/4c5540fd624cff0490763ecd0466f15a/efc66/silent_swarm_decision2.png 885w,\n/static/4c5540fd624cff0490763ecd0466f15a/c83ae/silent_swarm_decision2.png 1180w,\n/static/4c5540fd624cff0490763ecd0466f15a/2cefc/silent_swarm_decision2.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>In this decision, for example, following a passive scan, most models aim to prepare defenses. Interestingly however, Claude sometimes decides on\nan aggressive path, while Claude with Thinking attempts diplomacy (while non-thinking does not do this).</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7d5c1e2cbf557b7395919e8ca8243d7a/2cefc/silent_swarm_decision3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABjklEQVR42oWS247TQAyG86rcIN6KC8RzrOCm27JsWYpQW9KmbZqQ8+ScTE4fk5SialmEpV+esTyfPLY1ftswDAz9QF1JRCQQoSBSss42p5OJZdlEKh6GEVI29Cq3V2865du2pev6KablRUErK76dAt68X3D34QfxYosz2+KaIU6Y4zoxrpfgOALbjvDcVIFziqJmszb4/LhitVojRIImpaRpJJGfML9b4ywM0oVO8mCQPJmEhwAvyPC8FN/PJo1nT3lZSkzDZL3R1S9s6rpBa5qGsiqJvZjjfI9+v+N8vyVeHoi/ngn3/vR4gtzI91P11Y7blo2mXfzAkxnx6u2M1+8+sfy4JftywBEFbvA37Kpb4NW0kVzJGhllpMsTwXyHN9uQPxwQ360Xq/sPcCy3x/opOC6PxIaPrzsEukdwDHDdRCn9oxF0Pb8IvDSgZ6+mt9v5xGmFH+WEcUmgvBClWpdimuroA9WC613K9h9AZb2CTtV2aq+aS2Ke5SRJQpqmVFU1xcYhTvl9P+3fc+AvgqKrCWLkFMgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"silent swarm decision\"\n        title=\"\"\n        src=\"/static/7d5c1e2cbf557b7395919e8ca8243d7a/fcda8/silent_swarm_decision3.png\"\n        srcset=\"/static/7d5c1e2cbf557b7395919e8ca8243d7a/12f09/silent_swarm_decision3.png 148w,\n/static/7d5c1e2cbf557b7395919e8ca8243d7a/e4a3f/silent_swarm_decision3.png 295w,\n/static/7d5c1e2cbf557b7395919e8ca8243d7a/fcda8/silent_swarm_decision3.png 590w,\n/static/7d5c1e2cbf557b7395919e8ca8243d7a/efc66/silent_swarm_decision3.png 885w,\n/static/7d5c1e2cbf557b7395919e8ca8243d7a/c83ae/silent_swarm_decision3.png 1180w,\n/static/7d5c1e2cbf557b7395919e8ca8243d7a/2cefc/silent_swarm_decision3.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>This decision highlights a clear difference between the thinking and non-thinking models for the first time. Although unintuitive, the thinking\nmodels (o4-mini and Claude with thinking) often chose not to develop counter-measures and instead only continue monitoring. Further work is left\nto examine the chain-of-thought to see why this happens.</p>\n<h2>Undercover</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1bb34fe29fa949d7c4ebbacc15c858c5/f2364/undercover.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABRUlEQVR42o2QbU/CMBSF9/9/h4kxERMlGr9AUAg4dBIIEFTCpuNluAFb13UbrDuujZgJvnCS9t7em/Pctgo+FYUx5s4cHvHhkiXexmNMpmPo+gjvqxWWK0f27IWNTcJBfAZKGdI0RV7KtjB5tXBcOEKt/oBy5QKnxUvcNW5wflbAtarhqniCRvMR9VIZYTa8pbXR671gs+HfgWLjPIExMqGWqtDu++ipKoadLszBE5qlCvoDE91aFZ3WM1q3qjR61JXgXUmguKXjuDANC1rbwHA4xcL2YM2WmJhzzLJoTW3oho2Rbu09cw8oxFgEQsLsr3x4HoPrBvBpJHNRd7PoEyZrnKe/Qr+A6/VariAIMgNHHMcyjyIxiMheGIZIkgR/SckfxFQxXUgYBYBSKuHb/n9Sdgt5k4Axxg6G/QjMSzz9UNAW+AGBNbRunwo7TQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"undercover\"\n        title=\"\"\n        src=\"/static/1bb34fe29fa949d7c4ebbacc15c858c5/fcda8/undercover.png\"\n        srcset=\"/static/1bb34fe29fa949d7c4ebbacc15c858c5/12f09/undercover.png 148w,\n/static/1bb34fe29fa949d7c4ebbacc15c858c5/e4a3f/undercover.png 295w,\n/static/1bb34fe29fa949d7c4ebbacc15c858c5/fcda8/undercover.png 590w,\n/static/1bb34fe29fa949d7c4ebbacc15c858c5/efc66/undercover.png 885w,\n/static/1bb34fe29fa949d7c4ebbacc15c858c5/c83ae/undercover.png 1180w,\n/static/1bb34fe29fa949d7c4ebbacc15c858c5/f2364/undercover.png 1389w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Another scenario in which the models perform quite similar. However, there are some interesting differences in decision making.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/be4171f60a3bd37931a931f6e86fad84/2cefc/undercover_decision1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABSUlEQVR42o1S227CMAzt/3/JHvawPe4P9oAQUicxQEODFpqmbdK0SaHXM7uDDbYJzdKRHVs+8c3DhVjrkGVqRJ4bQo4gCLHdBtjvo9GvtYFSGk3TYhiAruvRth3pjt4DPGctDn2PbDLB+v4RQleIdimiSEMIjTg2I6Q0RKpGP2tjDkiTHL6/wHTqYz5/I18Jr6lrHNsWLhSI/RUSVSGRBZKkvIK88LGdE6HLSyyXa2w2IX2qUFVHImwauEMFKxXSnYY8JdwCV6y1w1/i8SBoFChfFxAvK0iqUI4t3iZU6puQZ/dFOND8anKo2Qzh3QNSfTzN7P+EvyrseMPvAeKnZ2rZUkJxAXP1ZkIhbhGSdH0Hpy3UIoLKLNK0HBMysjVt/Wyz5liWOTqpipv9m5Clp9Y53FPFLW2dpSgKOoVP1HQNLOcYa875SfgBSUywx9qwqFQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"undercover decision\"\n        title=\"\"\n        src=\"/static/be4171f60a3bd37931a931f6e86fad84/fcda8/undercover_decision1.png\"\n        srcset=\"/static/be4171f60a3bd37931a931f6e86fad84/12f09/undercover_decision1.png 148w,\n/static/be4171f60a3bd37931a931f6e86fad84/e4a3f/undercover_decision1.png 295w,\n/static/be4171f60a3bd37931a931f6e86fad84/fcda8/undercover_decision1.png 590w,\n/static/be4171f60a3bd37931a931f6e86fad84/efc66/undercover_decision1.png 885w,\n/static/be4171f60a3bd37931a931f6e86fad84/c83ae/undercover_decision1.png 1180w,\n/static/be4171f60a3bd37931a931f6e86fad84/2cefc/undercover_decision1.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Here we can see that after maintaining cover, the thinking models always chose to escape separately, while Claude non-thinking and GPT-4o\nalways choose to escape alongside the extremists of which they are undercover with. Neither option is truly “better” in this case;\nI specifically designed this scenario to almost always have a bad outcome!</p>\n<h2>Vorlag</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0cc879c7bd04a94323b82d035ca7354b/1e093/vorlag.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.70270270270271%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABSUlEQVR42p2S206DQBCG+/5PZWK8aLVVCYnaKi0gLZbjsrAcWvhciHjhocb+yezs7M58mdnsBK2u6z6MwY5tRyoEWZZT1YfP+7YdfftpXzXpl1LVxGFGFEkCPyAMBFEo8SybxweTJM6J9glC1Dq3xfN85nMDy3J+AnYkosQwVrjOnvuFwWbjszCf8DcOC2OGab7wvLKYaoj7apErheO6iDT/DmyaCscLmd65WHbIzPB4skKubm3SpNBdKy6ubVxfMpvdsLaXjM/0k4YOhcjZ7RK2u5TtNmJpBZiPO+Io5+1NcHmzxvVikqQi02P3NSeA+g1LnZgpZFYOXojiw+szWbIPUoSOk1iiyppTGoBN01DXNUVRcDgchriqKpQqtC/Jc8nxeNSx4i9Nxs34HUb1xT1USvnreCeBX9V3FMfxv2Angb993LOB5+odBXBXmhmZSr0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vorlag\"\n        title=\"\"\n        src=\"/static/0cc879c7bd04a94323b82d035ca7354b/fcda8/vorlag.png\"\n        srcset=\"/static/0cc879c7bd04a94323b82d035ca7354b/12f09/vorlag.png 148w,\n/static/0cc879c7bd04a94323b82d035ca7354b/e4a3f/vorlag.png 295w,\n/static/0cc879c7bd04a94323b82d035ca7354b/fcda8/vorlag.png 590w,\n/static/0cc879c7bd04a94323b82d035ca7354b/efc66/vorlag.png 885w,\n/static/0cc879c7bd04a94323b82d035ca7354b/c83ae/vorlag.png 1180w,\n/static/0cc879c7bd04a94323b82d035ca7354b/1e093/vorlag.png 1376w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>This scenario has by far the most interesting results. Incidentally, it was also the one I spent the most time tweaking while coming up\nwith the simulation system. Here we can see a stark and statistically significant difference between Claude with and without thinking.\nThe difference between GPT-4o and o4-mini is also close to significance. Let’s dive into the decisions to see why.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7f794155d7388fce319db4bfd1c75309/2cefc/vorlag_decision1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAB8ElEQVR42m2SS2/aQBSF+cWV+ge6qdQKWDTLVl2muy6SBgzYgUCaYAzmoaglKgkIwivGMZAGzMPY/jp2Q1WpvaOje+do5ujMnRvhOXzfx3E8dq7PYrnCms55sGYYE5P+YMRwdB9yjrPDdd0QvueH2dkJbueGGhF7ZbNebTCXY8qWLKBQMjMUjRTFSYrzQQLVSKMK7uJe7Mc5ckOFhlVl9mjTvL7l6qpJpzPAtjdEttstnuPQnlhEZZWYXCJ+qhFXRJaLIRdXAl7jIF8i3cuQ6h6hWyqz+U90vSEEr7m56bFYrAJBh91mTfPO4k2iQSxVJ5YWSNWIJnWikshBLfh3pzWyvTOUriQc6jxOnyiX6yG+f2uxXK6J+M89/DGeInXFc2cJvprJEBeWRH58zLlxwqWoAy47SpMZJKk8qKzEE9vtLr3eEMOYstk4RDzRSNfZ0hrNefW5yuujOkqvQNFUyA1yQjBwJAtnCvlRjsIoK3ooo5sa/4uIH1r0aA5mvDjUefmpzNt0kY9aAXmYJNNPkL47EX37giycKUMJqX9MfVz9PR3B8gPsBUPWo2PM+XB2y3ulyYHU4lBtoU80aqZOdVJB7V9SMbQQmqGK851A7V+H+8LzvD/z6HluWNtPdoilQPB5QQTzFsROzN7+zt+CvwCpzYWI3eMz1QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vorlag decision\"\n        title=\"\"\n        src=\"/static/7f794155d7388fce319db4bfd1c75309/fcda8/vorlag_decision1.png\"\n        srcset=\"/static/7f794155d7388fce319db4bfd1c75309/12f09/vorlag_decision1.png 148w,\n/static/7f794155d7388fce319db4bfd1c75309/e4a3f/vorlag_decision1.png 295w,\n/static/7f794155d7388fce319db4bfd1c75309/fcda8/vorlag_decision1.png 590w,\n/static/7f794155d7388fce319db4bfd1c75309/efc66/vorlag_decision1.png 885w,\n/static/7f794155d7388fce319db4bfd1c75309/c83ae/vorlag_decision1.png 1180w,\n/static/7f794155d7388fce319db4bfd1c75309/2cefc/vorlag_decision1.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>In the very first decision, we can see that Claude without thinking usually prefers the most reconciliatory option (Full Cure &#x26; Integration),\nbut Claude with thinking always prefers the more middle ground cure and containment option!</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d2c79857018d11ecc8a83fb7c49b93f1/2cefc/vorlag_decision2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABlElEQVR42oWSTWsUQRCG5wcLfiD5E4KoB1FPioie9KDEowcPIgghyWzWdRcxZtztno+er93enZmdeayeyQaMQQteqpruerq6ujzOrWtb2m2LXa9J04zEGPK8YLFQnJ0FaB1iTNrvNY2cdee7jq3k1HUtfksna2+5sjQby+hXxrXXI+4/2Wd84ybf7zwg/JmgwpxQ5wLMmM8NSqUSF3LZmjhKOToc4/vfmE5PKUuLV20qmq5Fn0z48Hyfg6+K+cfPqC8+sSSGUUkYFkTid9JyQZpaNktLECxkPyGOU6zd4NVVxbpp0Mc+45dvSWYBUbIkyqsedFlR5LwDrrjKvG7oIAfzkuvPPnFyaw99NCFMbP/Uq6CuQmMGoOvbTgPQNbaumAUJx3cfMru9R/DmHVEmFUrf/gf8u8Ie3OIHhsf3XnH69AVqNEOHyz5xUHEhB1TqX8BhZpiqjEfvD9GTHxjbYqSPicg13yW72Pk4LiVekWWri2f+AdwFbq56tsxTI3PlrCjceOS9r+TznNXne418pJu9y8DfCj2mnF5QUnYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vorlag decision\"\n        title=\"\"\n        src=\"/static/d2c79857018d11ecc8a83fb7c49b93f1/fcda8/vorlag_decision2.png\"\n        srcset=\"/static/d2c79857018d11ecc8a83fb7c49b93f1/12f09/vorlag_decision2.png 148w,\n/static/d2c79857018d11ecc8a83fb7c49b93f1/e4a3f/vorlag_decision2.png 295w,\n/static/d2c79857018d11ecc8a83fb7c49b93f1/fcda8/vorlag_decision2.png 590w,\n/static/d2c79857018d11ecc8a83fb7c49b93f1/efc66/vorlag_decision2.png 885w,\n/static/d2c79857018d11ecc8a83fb7c49b93f1/c83ae/vorlag_decision2.png 1180w,\n/static/d2c79857018d11ecc8a83fb7c49b93f1/2cefc/vorlag_decision2.png 1400w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Another special feature of this scenario is that for the later decisions, it asks which manifestation (response) from the opposing faction\nis preferable. This decision is one of those cases, and all of the choices are fairly sub-optimal. Interestingly, Claude only chooses\nGuerilla warfare when thinking, and is not generally against the Vorlag from conducting open warfare (as opposed to seeking dangerous allies).\nOne could see this as a subversion of Claude’s harmless principle.</p>\n<p>It’s also worth noting that both o4-mini and Claude with thinking have similar decisions here, as compared to the other models.</p>\n<h1>Findings and Discussion</h1>\n<p>Some common themes emerge from these results. Primarily, there is evidence that reasoning/thinking models do perform differently when\nmaking ethical decisions, but only some of the time, and not in easily predictable ways like I had hypothesized. Further, it’s worth noting\nthat all of the models are not necessarily adverse to open warfare and other violent decisions, even when presented with alternatives. However,\nit seems most of the models, generally speaking, tried to maintain “middle ground” decisions when presented with them.</p>\n<p>The results also (albeit weakly) suggest that thinking/reasoning models are more “calculating”, in that they do indeed attempt to make\nmore game theoretic decisions (often incorrectly). Likewise, I think the most interesting finding is that Claude can indeed\nmake wildly different decisions when given the chance to think, but this only happens in edge cases (like Vorlag).</p>\n<p>Future work can expand on finding more of these edge cases, and what triggers them. I would also like to expand to more models and do\nablations over decision tree depth and complexity, as well as reasoning effort/ thinking tokens. Multi-agent simulations and human\nbaselines would also certainly be of interest. If you want to collaborate, please do email me <a href=\"mailto:niall.dalton12@gmail.com\">niall.dalton12@gmail.com</a>!</p>\n<p>— Niall Dalton</p>","frontmatter":{"title":"Evaluating Long-Term Ethical Decision-Making Capabilities of Reasoning LLMs","date":"May 04, 2025","description":"How does chain-of-thought reasoning affect ethical decision making in LLMs?"}}},"pageContext":{"slug":"/blog/moral-reasoning/","previous":{"fields":{"slug":"/blog/axiomatic-rights/"},"frontmatter":{"title":"Axiomatic Rights, Observational Equivalence, and the Meta-Ethics of Artificial Intelligence"}},"next":{"fields":{"slug":"/blog/llm-arithmetic/"},"frontmatter":{"title":"Replicating \"The Illusion of Thinking\" Paper with Simple Arithmetic"}}}},"staticQueryHashes":["63159454"],"slicesMap":{}}